{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import SVC\n\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv('../input/test.csv')\ntrain","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fea32f89-e062-49dc-bd39-31de129991be","_uuid":"d05192891645ab3906a32602da6d31a3cb78729f","trusted":true},"cell_type":"code","source":"# train.info()\n# train.describe()\n# train.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ae310f5e-1685-421b-8e94-e2cc7f3f9063","_uuid":"0683312d83579032a41ebbd1d04bfbbeb5ffa077","trusted":true},"cell_type":"code","source":"y_train = train['Survived']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"30a43f03-b446-4c17-ab37-91e6bb7e2e57","_uuid":"8a4516eb2f0dd77236620090ebaf70da3054858b","trusted":true},"cell_type":"code","source":"train.drop(['Survived'], axis=1, inplace=True)\n\n# survive_rate = len(y[y==1])/len(y)  # survive rate is 38.38%\n# train['Cabin'] = pd.factorize(train['Cabin'])[0]\ntrain.drop(['Cabin'], axis=1, inplace=True)\ntrain['Embarked'].fillna('S', inplace=True)  # fill nan in Embarked with top freq 'S'\ntrain['Embarked'] = pd.factorize(train['Embarked'])[0]\ntrain['Ticket'] = pd.factorize(train['Ticket'])[0]\n# train.drop(['Ticket'], axis=1, inplace=True)\n\ntrain['Sex'] = pd.factorize(train['Sex'])[0]\n\n# the title in the Name may highly correlated with Age Sex, so drop the Name col\n# now all the categorical data has been convert to numerical data\ntrain.drop(['PassengerId'], axis=1, inplace=True)\nX_train = train","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"188c3e06-4680-41e4-b81c-d5c2a86b6dd5","_uuid":"8b58f3481228a94f5c4f53fa651f12a93d778920","trusted":true},"cell_type":"code","source":"\nX_train['Title'] = X_train['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\nX_train['Title'] = X_train['Title'].replace('Mlle', 'Miss')\nX_train['Title'] = X_train['Title'].replace('Ms', 'Miss')\nX_train['Title'] = X_train['Title'].replace('Mme', 'Mrs')\n\nX_train['Title'] = X_train['Title'].replace('Rev', 'Mr')\n\nX_train['Title'] = X_train['Title'].replace(['Capt', 'Col', 'Countess', 'Don', 'Dr', 'Major', 'Sir', 'Jonkheer', 'Lady'], 'Noble')\n# X_train.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a664e290-6482-448d-a20e-00bc651161e9","_uuid":"80336977835fce6363294c8ef59e6ce2ce47f442","trusted":true},"cell_type":"code","source":"X_age = X_train.dropna(axis=0)\nX_age_class = X_age.groupby('Pclass').agg({'Age': np.average})\nX_age_title = X_age.groupby('Title').agg({'Age': np.average})\nprint(X_age.groupby('Pclass').agg({'Age': np.average}))\nprint(X_age.groupby('Title').agg({'Age': np.average}))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a3f4f9e8-22db-4c55-811e-41b693aa31f6","_uuid":"3187e6ce11807f6461106bda037cf4d47366886d","trusted":true},"cell_type":"code","source":"X_age_title.loc['Master']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b96481a0-81b2-473d-91d7-b6518a6f9410","_uuid":"3d5571d124d35fc625ae20e74c39c668ddb48883","trusted":true},"cell_type":"code","source":"X_train['Age'].fillna(0, inplace=True)\nX_train.drop('Name', axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2e3fba19-e550-4723-b65a-fddfed9f90e8","_uuid":"5029486ab0b2d39dbd82c4bf2aa0685e32c75ef3","trusted":true},"cell_type":"code","source":"X_train_M_age = X_train[X_train['Age'] == 0]\nX_train_M_age\n# for cla in X_train_M_age['Pclass']:\n#     for title in X_train_M_age['Title']:\n#         X_train_M_age[(X_train_M_age['Pclass'] == cla) & (X_train_M_age['Title'] == title)]['Age'] = (X_age_class.loc[cla] + X_age_title.loc[title]) / 2\n# X_train_M_age","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7d51a34a-2f30-423b-a978-7d4b42b1ad53","_uuid":"eb2c13c8bc4f233dc4a90683b96378050d6d4224","trusted":true},"cell_type":"code","source":"# fill missing ages\n# ------------------------------------\ntrain = pd.read_csv(\"../input/train.csv\")\n\ny = train['Survived']\n\ntrain.drop(['Survived'], axis=1, inplace=True)\n\ntrain.drop(['Cabin'], axis=1, inplace=True)\ntrain['Embarked'].fillna('S', inplace=True)  # fill nan in Embarked with top freq 'S'\ntrain['Embarked'] = pd.factorize(train['Embarked'])[0]\ntrain['Ticket'] = pd.factorize(train['Ticket'])[0]\ntrain['Sex'] = pd.factorize(train['Sex'])[0]\ntrain.drop(['PassengerId'], axis=1, inplace=True)\n\ntrain['Title'] = train['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')\ntrain['Title'] = train['Title'].replace('Rev', 'Mr')\n\ntrain['Title'] = train['Title'].replace(['Capt', 'Col', 'Countess', 'Don',\n                                         'Dr', 'Major', 'Sir', 'Jonkheer', 'Lady'], 'Noble')\n\nX_age = train.dropna(axis=0)\nX_age_class = X_age.groupby('Pclass').agg({'Age': np.average})\nX_age_title = X_age.groupby('Title').agg({'Age': np.average})\nprint(X_age.groupby('Pclass').agg({'Age': np.average}))\nprint(X_age.groupby('Title').agg({'Age': np.average}))\n\ntrain['Age'].fillna(0, inplace=True)\ntrain.drop('Name', axis=1, inplace=True)\n\nX_train_M_age = train[train['Age'] == 0]\n\nX_train_M_age.set_value(X_train_M_age[X_train_M_age['Title'] == 'Master'].index,\n                        'Age', X_age_title.loc['Master'].item())\nX_train_M_age.set_value(X_train_M_age[X_train_M_age['Title'] == 'Noble'].index,\n                        'Age', X_age_title.loc['Noble'].item())\n\nfor cla in X_train_M_age['Pclass']:\n    for title in ['Miss', 'Mr', 'Mrs']:\n        X_train_M_age.set_value(X_train_M_age[(X_train_M_age['Pclass'] == cla) & (X_train_M_age['Title'] == title)].index, 'Age',\n         (X_age_class.loc[cla].item() + X_age_title.loc[title].item()) / 2)\n        \ntrain.set_value(train[train['Age'] == 0].index, 'Age', X_train_M_age['Age'].values)  # set missing ages completed\n\ntrain['Title'] = pd.factorize(train['Title'])[0] + 1\ntrain['Embarked'] = train['Embarked'] + 1\ntrain['Ticket'] = train['Ticket'] + 1\ntrain['Sex'] = train['Sex'] + 1\n\n\nX_train = train.drop('Ticket', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4b153b8f-f385-4cca-a5da-4984aecdde9d","_uuid":"18ddb9622c7bd7bee4d8c51698615134e5e79221","trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')\n# test\ntest.info()  # notice there is additional Null in fare of test\ntest['Title'] = test['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\nX_age = test.dropna(axis=0)\nX_age_title = X_age.groupby('Title').agg({'Age': np.average})\nX_age_title","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d65481bc-cd40-410c-a80e-9f120585e3e0","_uuid":"7ef769f69b1e7bcb7b28e76a869b34cff4c61d46","trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')\ntest.drop(['Cabin'], axis=1, inplace=True)\ntest.fillna(test['Fare'].mean(), inplace=True)\ntest['Embarked'] = pd.factorize(test['Embarked'])[0]\ntest['Sex'] = pd.factorize(test['Sex'])[0]\ntest.drop(['PassengerId'], axis=1, inplace=True)\n\ntest['Title'] = test['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n\ntest['Title'] = test['Title'].replace(['Col', 'Dr', 'Dona'], 'Noble')\n\nX_age = test.dropna(axis=0)\nX_age_class = X_age.groupby('Pclass').agg({'Age': np.average})\nX_age_title = X_age.groupby('Title').agg({'Age': np.average})\n\ntest['Age'].fillna(0, inplace=True)\ntest.drop('Name', axis=1, inplace=True)\n\nX_test_M_age = test[test['Age'] == 0]\n\nX_test_M_age.set_value(X_test_M_age[X_test_M_age['Title'] == 'Master'].index,\n                        'Age', X_age_title.loc['Master'].item())\nX_test_M_age.set_value(X_test_M_age[X_test_M_age['Title'] == 'Noble'].index,\n                        'Age', X_age_title.loc['Noble'].item())\n\nfor cla in X_test_M_age['Pclass']:\n    for title in ['Miss', 'Mr', 'Mrs']:\n        X_test_M_age.set_value(X_test_M_age[(X_test_M_age['Pclass'] == cla) & (X_test_M_age['Title'] == title)].index, 'Age',\n         (X_age_class.loc[cla].item() + X_age_title.loc[title].item()) / 2)\n        \ntest.set_value(test[test['Age'] == 0].index, 'Age', X_test_M_age['Age'].values)  # set missing ages completed\n\ntest['Title'] = pd.factorize(test['Title'])[0] + 1\ntest['Embarked'] = test['Embarked'] + 1\ntest['Sex'] = test['Sex'] + 1\n\nX_test = test.drop('Ticket', axis=1)\n\nX_test.info()\n# X_test","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56070a93-05e8-4b5f-8883-209b8e3b99a7","_uuid":"8a50b7f7456d058476bdb31e23cda1ced38d156a","trusted":true},"cell_type":"code","source":"# Important for logistic regression, svm, NN\n# important to introduce the normalization to deal with verious feature scales\nX_train_scaled = MinMaxScaler().fit_transform(X_train)\nX_test_scaled = MinMaxScaler().fit_transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f22a9aa7-0044-4cd1-9de3-90a1a83e53f9","_uuid":"ed9b829f9f1a467024da6c4e3274defd1fb890dc","trusted":true},"cell_type":"code","source":"# logistic regression\n# For better fit, bigger C values specify weaker regularization\nlr = LogisticRegression(C=10).fit(X_train_scaled, y_train)\ntrain_score = lr.score(X_train_scaled, y_train)\ntrain_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"65872437-b9e2-4c0b-808f-8132143eb2f3","_uuid":"8685e596842e8ea6c9c0707df7cf2dd485556522","trusted":true},"cell_type":"code","source":"# see the output requirement\noutput = pd.read_csv('../input/gender_submission.csv')\noutput","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"53c72aef-826c-44f4-ac22-9a489e98b0df","_uuid":"07007cd0be7dbc1e285f7a6f0e764bf479c0fd3d","trusted":false},"cell_type":"code","source":"y_pre_lr = lr.predict(X_test_scaled)\nout_lr = pd.DataFrame({'PassengerId': test['PassengerId'].values, 'Survived': y_pre_lr})\n#out_lr","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1a2b1d1e-d928-4012-bd8d-a7772fd31f13","_uuid":"7bca5bf2a15a3295b12c85254808697a4ad2dec5","trusted":false},"cell_type":"code","source":"# SVM\nsvm = SVC(gamma=1, C=250).fit(X_train_scaled, y_train)\ntrain_score = svm.score(X_train_scaled, y_train)\ntrain_score\n\n# train_score = []\n# for this_gamma in [0.01, 1, 5]:\n#     for this_C in [0.1, 1, 15, 250]:\n#         svm = SVC(kernel='rbf', gamma=this_gamma, C=this_C).fit(X_train_scaled, y_train)\n#         train_score.append(svm.score(X_train_scaled, y_train))\n# train_score","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"58ff8b25-f4fb-4b5d-9806-21bbc1dea207","_uuid":"f1d6ab14432491998742777516f7bc4adc7afeb3","trusted":false},"cell_type":"code","source":"y_pre_svm = svm.predict(X_test_scaled)\nout_svm = pd.DataFrame({'PassengerId': test['PassengerId'].values, 'Survived': y_pre_svm})\n# out_svm","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"7d4afe2d-0128-47df-ab72-e040be94dd43","_uuid":"9df982208b66eb0fcfa33ef040deb7373fca2687","trusted":false},"cell_type":"code","source":"# Naive Bayes Classifier, Highly efficient but bad generalization\nnb = GaussianNB().fit(X_train_scaled, y_train)\ntrain_score = nb.score(X_train_scaled, y_train)\ntrain_score  # tend to overfit, because features are many","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"62b3efea-ae62-4114-907d-4f8572f95302","_uuid":"11877b9a713ed664819dbdd0bad0648668ede41b","trusted":false},"cell_type":"code","source":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3).fit(X_train_scaled, y_train)\ny_pre_knn = knn.predict(X_test_scaled)\ntrain_score = knn.score(X_train_scaled, y_train)\ntrain_score","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"31003e64-7198-4594-8aa0-9b035b9cdba6","_uuid":"e8c9cddfff60ce3d55bfbecccfe487f3bf577492","trusted":false},"cell_type":"code","source":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(max_depth=4, min_samples_leaf=10).fit(X_train, y_train)\ny_pre_tree = tree.predict(X_test)\ntrain_score = tree.score(X_train, y_train)\ntrain_score\n# train_score=[]\n# for depth in [3, 5, 10, 20, 50]:\n#     tree = DecisionTreeClassifier(max_depth=depth).fit(X_train_scaled, y_train)\n#     train_score.append(tree.score(X_train_scaled, y_train))\n# train_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a7c4a581-988f-4042-9e3a-8f7ea008df71","_uuid":"17d30f80c026a0f2b161295d6fb473e3ffb894ac","trusted":false},"cell_type":"code","source":"# Neural Networks\nfrom sklearn.neural_network import MLPClassifier\n\nNN = MLPClassifier(hidden_layer_sizes=[100, 100], solver='adam', max_iter=300,\n                   random_state=1).fit(X_train_scaled, y_train)\ny_pre_NN = NN.predict(X_test_scaled)\ntrain_score = NN.score(X_train_scaled, y_train)\ntrain_score\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dc03f5f6-6f4a-4984-ac0c-4d8b6107c963","_uuid":"6e3e96a36a9b1594acad07979aedbb301a956f99","trusted":true},"cell_type":"code","source":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=49, max_features='auto', random_state=0).fit(X_train, y_train)\ny_pre_rf = rf.predict(X_test)\ntrain_score = rf.score(X_train, y_train)\ntrain_score","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_cell_guid":"70b8ed9f-831b-4aaa-9e82-ba34dcaf85d0","_kg_hide-input":false,"_uuid":"175bfe392644d8832a016fbef3ea138c3d566dbe","trusted":false},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')\n# select one algorithm according to the performance on trainning set\noutput = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_pre_NN})\noutput.to_csv('prediction_NN.csv', index=False)\noutput","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom matplotlib import pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split(X, y):\n    X_cv, X_dev, y_cv, y_dev = train_test_split(X, y, test_size=0.2, random_state=0)\n\n    return X_cv, X_dev, y_cv, y_dev","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ecb953a4-2c37-42ef-8dc4-63240d90067c","_uuid":"ddb937b3d004ccb578e6a9cd58166a7eaac1048b","trusted":true},"cell_type":"code","source":"def grid_search_cross_validation(X_cv, X_dev, y_cv, y_dev, save_csv=False):\n#     model = SVC()\n#     parameters = {'C': [2], 'kernel': ['rbf'],\n#                   'gamma': ['scale'], 'random_state': [0]}  # larger the gamma, more complex the kernel\n\n    # model = DecisionTreeClassifier()\n    # parameters = {'max_depth': [13], 'max_features': [600], 'random_state': [0]}\n\n    # model = LogisticRegression()\n    # parameters = {'C': [2], 'solver': ['liblinear'], 'random_state': [0]}\n\n    model = RandomForestClassifier()\n    parameters = {'n_estimators': [10, 50, 100, 150], 'max_features': ['auto', 'sqrt', 'log2', None], \n                  'max_depth': [5, 10, 20],\n                  'min_samples_leaf': [1, 2, 3],\n                  'random_state': [0], 'n_jobs': [8]}\n\n#     model = MLPClassifier()\n#     parameters = {'hidden_layer_sizes': [(50, )], 'activation': ['relu'], 'solver': ['adam'],\n#                   'max_iter': [1000], 'early_stopping': [False],\n#                   'alpha': [0], 'random_state': [0]}\n\n    # model = KNeighborsClassifier()\n    # parameters = {'n_neighbors': [10], 'weights': ['distance'], 'n_jobs': [8]}\n\n    clf = GridSearchCV(estimator=model, param_grid=parameters, return_train_score=True, cv=3)\n    clf.fit(X_cv, y_cv)\n\n    grid_search_results = pd.DataFrame(clf.cv_results_)\n    if save_csv:\n        # output grid search results as a csv file\n        algorithm = str(model).split('(')[0]\n        grid_search_results.to_csv(os.path.join(save_dir, algorithm + ' parameter grid search results.csv'))\n\n    pd.set_option('display.max_columns', None)\n    print(grid_search_results)\n    print('best score: ' + str(clf.best_score_))\n    print('best parameters: ' + str(clf.best_params_))\n    \n    best_estimator = clf.best_estimator_\n    test_score = best_estimator.score(X_dev, y_dev)\n    print('best estimator test score: ' + str(test_score))\n","execution_count":77,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run():\n    X = X_train\n    y = y_train\n    X_cv, X_dev, y_cv, y_dev = split(X, y)\n    grid_search_cross_validation(X_cv, X_dev, y_cv, y_dev, save_csv=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run()","execution_count":78,"outputs":[{"output_type":"stream","text":"     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0         0.057635      0.041938         0.105364        0.000091   \n1         0.097882      0.003365         0.105319        0.000246   \n2         0.145651      0.003907         0.105262        0.000365   \n3         0.186912      0.004614         0.105076        0.000286   \n4         0.028960      0.000672         0.105121        0.000460   \n5         0.096591      0.000952         0.105361        0.000091   \n6         0.134992      0.005084         0.105058        0.000216   \n7         0.174935      0.008265         0.105082        0.000229   \n8         0.029957      0.001071         0.104906        0.000309   \n9         0.093398      0.002578         0.105112        0.000212   \n10        0.139955      0.007579         0.105133        0.000109   \n11        0.181448      0.010597         0.104730        0.000285   \n12        0.029931      0.002101         0.104916        0.000076   \n13        0.096648      0.002856         0.104998        0.000131   \n14        0.145036      0.010308         0.104915        0.000214   \n15        0.182365      0.008590         0.104721        0.000355   \n16        0.027987      0.000766         0.104672        0.000195   \n17        0.093251      0.001528         0.104998        0.000080   \n18        0.140677      0.005219         0.106044        0.001601   \n19        0.181404      0.003782         0.105188        0.000086   \n20        0.030071      0.002733         0.104748        0.000126   \n21        0.095222      0.001082         0.104976        0.000267   \n22        0.146056      0.008645         0.105007        0.000183   \n23        0.181585      0.007948         0.104662        0.000258   \n24        0.027044      0.001442         0.104631        0.000085   \n25        0.097000      0.000620         0.104789        0.000263   \n26        0.141876      0.005002         0.104937        0.000239   \n27        0.184073      0.005305         0.105408        0.000378   \n28        0.027668      0.002095         0.104638        0.000199   \n29        0.095508      0.000878         0.104936        0.000054   \n..             ...           ...              ...             ...   \n114       0.151144      0.004644         0.104840        0.000117   \n115       0.188841      0.010273         0.105028        0.000385   \n116       0.030578      0.000266         0.104281        0.000200   \n117       0.100535      0.003778         0.104821        0.000233   \n118       0.139391      0.007698         0.104980        0.000460   \n119       0.179682      0.002062         0.104764        0.000250   \n120       0.029139      0.002173         0.104829        0.000079   \n121       0.097445      0.008227         0.104872        0.000121   \n122       0.146386      0.002567         0.104974        0.000092   \n123       0.191902      0.007263         0.104884        0.000223   \n124       0.029984      0.000636         0.104916        0.000162   \n125       0.100919      0.001299         0.104764        0.000268   \n126       0.149522      0.010875         0.105230        0.000145   \n127       0.177480      0.007481         0.104743        0.000042   \n128       0.029205      0.001143         0.104801        0.000420   \n129       0.099818      0.004096         0.104876        0.000141   \n130       0.150244      0.003586         0.104964        0.000219   \n131       0.188613      0.007584         0.104928        0.000233   \n132       0.029282      0.001743         0.104702        0.000100   \n133       0.109283      0.002576         0.104707        0.000151   \n134       0.163195      0.010874         0.105152        0.000183   \n135       0.195510      0.003014         0.104990        0.000346   \n136       0.029762      0.001417         0.104676        0.000074   \n137       0.107526      0.002079         0.105064        0.000124   \n138       0.146380      0.011955         0.104858        0.000403   \n139       0.193994      0.004140         0.104718        0.000172   \n140       0.031178      0.000626         0.104897        0.000254   \n141       0.111706      0.001030         0.104890        0.000428   \n142       0.176807      0.044301         0.105157        0.000079   \n143       0.204657      0.008018         0.105197        0.000118   \n\n    param_max_depth param_max_features param_min_samples_leaf  \\\n0                 5               auto                      1   \n1                 5               auto                      1   \n2                 5               auto                      1   \n3                 5               auto                      1   \n4                 5               auto                      2   \n5                 5               auto                      2   \n6                 5               auto                      2   \n7                 5               auto                      2   \n8                 5               auto                      3   \n9                 5               auto                      3   \n10                5               auto                      3   \n11                5               auto                      3   \n12                5               sqrt                      1   \n13                5               sqrt                      1   \n14                5               sqrt                      1   \n15                5               sqrt                      1   \n16                5               sqrt                      2   \n17                5               sqrt                      2   \n18                5               sqrt                      2   \n19                5               sqrt                      2   \n20                5               sqrt                      3   \n21                5               sqrt                      3   \n22                5               sqrt                      3   \n23                5               sqrt                      3   \n24                5               log2                      1   \n25                5               log2                      1   \n26                5               log2                      1   \n27                5               log2                      1   \n28                5               log2                      2   \n29                5               log2                      2   \n..              ...                ...                    ...   \n114              20               sqrt                      2   \n115              20               sqrt                      2   \n116              20               sqrt                      3   \n117              20               sqrt                      3   \n118              20               sqrt                      3   \n119              20               sqrt                      3   \n120              20               log2                      1   \n121              20               log2                      1   \n122              20               log2                      1   \n123              20               log2                      1   \n124              20               log2                      2   \n125              20               log2                      2   \n126              20               log2                      2   \n127              20               log2                      2   \n128              20               log2                      3   \n129              20               log2                      3   \n130              20               log2                      3   \n131              20               log2                      3   \n132              20               None                      1   \n133              20               None                      1   \n134              20               None                      1   \n135              20               None                      1   \n136              20               None                      2   \n137              20               None                      2   \n138              20               None                      2   \n139              20               None                      2   \n140              20               None                      3   \n141              20               None                      3   \n142              20               None                      3   \n143              20               None                      3   \n\n    param_n_estimators param_n_jobs param_random_state  \\\n0                   10            8                  0   \n1                   50            8                  0   \n2                  100            8                  0   \n3                  150            8                  0   \n4                   10            8                  0   \n5                   50            8                  0   \n6                  100            8                  0   \n7                  150            8                  0   \n8                   10            8                  0   \n9                   50            8                  0   \n10                 100            8                  0   \n11                 150            8                  0   \n12                  10            8                  0   \n13                  50            8                  0   \n14                 100            8                  0   \n15                 150            8                  0   \n16                  10            8                  0   \n17                  50            8                  0   \n18                 100            8                  0   \n19                 150            8                  0   \n20                  10            8                  0   \n21                  50            8                  0   \n22                 100            8                  0   \n23                 150            8                  0   \n24                  10            8                  0   \n25                  50            8                  0   \n26                 100            8                  0   \n27                 150            8                  0   \n28                  10            8                  0   \n29                  50            8                  0   \n..                 ...          ...                ...   \n114                100            8                  0   \n115                150            8                  0   \n116                 10            8                  0   \n117                 50            8                  0   \n118                100            8                  0   \n119                150            8                  0   \n120                 10            8                  0   \n121                 50            8                  0   \n122                100            8                  0   \n123                150            8                  0   \n124                 10            8                  0   \n125                 50            8                  0   \n126                100            8                  0   \n127                150            8                  0   \n128                 10            8                  0   \n129                 50            8                  0   \n130                100            8                  0   \n131                150            8                  0   \n132                 10            8                  0   \n133                 50            8                  0   \n134                100            8                  0   \n135                150            8                  0   \n136                 10            8                  0   \n137                 50            8                  0   \n138                100            8                  0   \n139                150            8                  0   \n140                 10            8                  0   \n141                 50            8                  0   \n142                100            8                  0   \n143                150            8                  0   \n\n                                                params  split0_test_score  \\\n0    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.794118   \n1    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.810924   \n2    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.806723   \n3    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.806723   \n4    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.806723   \n5    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.806723   \n6    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.806723   \n7    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.806723   \n8    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.789916   \n9    {'max_depth': 5, 'max_features': 'auto', 'min_...           0.806723   \n10   {'max_depth': 5, 'max_features': 'auto', 'min_...           0.806723   \n11   {'max_depth': 5, 'max_features': 'auto', 'min_...           0.806723   \n12   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.794118   \n13   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.810924   \n14   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.806723   \n15   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.806723   \n16   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.806723   \n17   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.806723   \n18   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.806723   \n19   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.806723   \n20   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.789916   \n21   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.806723   \n22   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.806723   \n23   {'max_depth': 5, 'max_features': 'sqrt', 'min_...           0.806723   \n24   {'max_depth': 5, 'max_features': 'log2', 'min_...           0.806723   \n25   {'max_depth': 5, 'max_features': 'log2', 'min_...           0.819328   \n26   {'max_depth': 5, 'max_features': 'log2', 'min_...           0.815126   \n27   {'max_depth': 5, 'max_features': 'log2', 'min_...           0.815126   \n28   {'max_depth': 5, 'max_features': 'log2', 'min_...           0.819328   \n29   {'max_depth': 5, 'max_features': 'log2', 'min_...           0.815126   \n..                                                 ...                ...   \n114  {'max_depth': 20, 'max_features': 'sqrt', 'min...           0.810924   \n115  {'max_depth': 20, 'max_features': 'sqrt', 'min...           0.815126   \n116  {'max_depth': 20, 'max_features': 'sqrt', 'min...           0.802521   \n117  {'max_depth': 20, 'max_features': 'sqrt', 'min...           0.815126   \n118  {'max_depth': 20, 'max_features': 'sqrt', 'min...           0.810924   \n119  {'max_depth': 20, 'max_features': 'sqrt', 'min...           0.810924   \n120  {'max_depth': 20, 'max_features': 'log2', 'min...           0.785714   \n121  {'max_depth': 20, 'max_features': 'log2', 'min...           0.802521   \n122  {'max_depth': 20, 'max_features': 'log2', 'min...           0.794118   \n123  {'max_depth': 20, 'max_features': 'log2', 'min...           0.794118   \n124  {'max_depth': 20, 'max_features': 'log2', 'min...           0.802521   \n125  {'max_depth': 20, 'max_features': 'log2', 'min...           0.823529   \n126  {'max_depth': 20, 'max_features': 'log2', 'min...           0.819328   \n127  {'max_depth': 20, 'max_features': 'log2', 'min...           0.806723   \n128  {'max_depth': 20, 'max_features': 'log2', 'min...           0.831933   \n129  {'max_depth': 20, 'max_features': 'log2', 'min...           0.819328   \n130  {'max_depth': 20, 'max_features': 'log2', 'min...           0.819328   \n131  {'max_depth': 20, 'max_features': 'log2', 'min...           0.815126   \n132  {'max_depth': 20, 'max_features': None, 'min_s...           0.794118   \n133  {'max_depth': 20, 'max_features': None, 'min_s...           0.794118   \n134  {'max_depth': 20, 'max_features': None, 'min_s...           0.798319   \n135  {'max_depth': 20, 'max_features': None, 'min_s...           0.798319   \n136  {'max_depth': 20, 'max_features': None, 'min_s...           0.810924   \n137  {'max_depth': 20, 'max_features': None, 'min_s...           0.815126   \n138  {'max_depth': 20, 'max_features': None, 'min_s...           0.806723   \n139  {'max_depth': 20, 'max_features': None, 'min_s...           0.815126   \n140  {'max_depth': 20, 'max_features': None, 'min_s...           0.831933   \n141  {'max_depth': 20, 'max_features': None, 'min_s...           0.823529   \n142  {'max_depth': 20, 'max_features': None, 'min_s...           0.815126   \n143  {'max_depth': 20, 'max_features': None, 'min_s...           0.823529   \n\n     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n0             0.848101           0.818565         0.820225        0.022078   \n1             0.848101           0.831224         0.830056        0.015205   \n2             0.843882           0.835443         0.828652        0.015916   \n3             0.839662           0.843882         0.830056        0.016623   \n4             0.839662           0.822785         0.823034        0.013453   \n5             0.843882           0.831224         0.827247        0.015433   \n6             0.843882           0.839662         0.830056        0.016623   \n7             0.839662           0.839662         0.828652        0.015539   \n8             0.843882           0.814346         0.816011        0.022071   \n9             0.843882           0.831224         0.827247        0.015433   \n10            0.843882           0.839662         0.830056        0.016623   \n11            0.843882           0.827004         0.825843        0.015198   \n12            0.848101           0.818565         0.820225        0.022078   \n13            0.848101           0.831224         0.830056        0.015205   \n14            0.843882           0.835443         0.828652        0.015916   \n15            0.839662           0.843882         0.830056        0.016623   \n16            0.839662           0.822785         0.823034        0.013453   \n17            0.843882           0.831224         0.827247        0.015433   \n18            0.843882           0.839662         0.830056        0.016623   \n19            0.839662           0.839662         0.828652        0.015539   \n20            0.843882           0.814346         0.816011        0.022071   \n21            0.843882           0.831224         0.827247        0.015433   \n22            0.843882           0.839662         0.830056        0.016623   \n23            0.843882           0.827004         0.825843        0.015198   \n24            0.814346           0.827004         0.816011        0.008366   \n25            0.839662           0.831224         0.830056        0.008345   \n26            0.839662           0.822785         0.825843        0.010251   \n27            0.839662           0.839662         0.831461        0.011575   \n28            0.822785           0.793249         0.811798        0.013178   \n29            0.839662           0.835443         0.830056        0.010719   \n..                 ...                ...              ...             ...   \n114           0.835443           0.814346         0.820225        0.010840   \n115           0.835443           0.814346         0.821629        0.009763   \n116           0.822785           0.810127         0.811798        0.008359   \n117           0.831224           0.827004         0.824438        0.006819   \n118           0.835443           0.822785         0.823034        0.010015   \n119           0.831224           0.822785         0.821629        0.008330   \n120           0.827004           0.797468         0.803371        0.017370   \n121           0.818565           0.818565         0.813202        0.007569   \n122           0.827004           0.810127         0.810393        0.013432   \n123           0.822785           0.810127         0.808989        0.011735   \n124           0.839662           0.793249         0.811798        0.020043   \n125           0.835443           0.814346         0.824438        0.008631   \n126           0.848101           0.818565         0.828652        0.013742   \n127           0.839662           0.822785         0.823034        0.013453   \n128           0.835443           0.827004         0.831461        0.003459   \n129           0.848101           0.818565         0.828652        0.013742   \n130           0.848101           0.831224         0.832865        0.011808   \n131           0.843882           0.831224         0.830056        0.011773   \n132           0.797468           0.772152         0.787921        0.011223   \n133           0.818565           0.797468         0.803371        0.010820   \n134           0.839662           0.797468         0.811798        0.019686   \n135           0.822785           0.793249         0.804775        0.012889   \n136           0.810127           0.780591         0.800562        0.014111   \n137           0.827004           0.814346         0.818820        0.005790   \n138           0.822785           0.810127         0.813202        0.006910   \n139           0.843882           0.805907         0.821629        0.016163   \n140           0.835443           0.801688         0.823034        0.015146   \n141           0.835443           0.805907         0.821629        0.012124   \n142           0.827004           0.818565         0.820225        0.004991   \n143           0.831224           0.814346         0.823034        0.006894   \n\n     rank_test_score  split0_train_score  split1_train_score  \\\n0                 87            0.858650            0.844211   \n1                 15            0.858650            0.844211   \n2                 29            0.860759            0.856842   \n3                 15            0.858650            0.854737   \n4                 65            0.862869            0.844211   \n5                 42            0.854430            0.840000   \n6                 15            0.856540            0.852632   \n7                 29            0.856540            0.848421   \n8                106            0.843882            0.842105   \n9                 42            0.848101            0.842105   \n10                15            0.852321            0.844211   \n11                50            0.852321            0.846316   \n12                87            0.858650            0.844211   \n13                15            0.858650            0.844211   \n14                29            0.860759            0.856842   \n15                15            0.858650            0.854737   \n16                65            0.862869            0.844211   \n17                42            0.854430            0.840000   \n18                15            0.856540            0.852632   \n19                29            0.856540            0.848421   \n20               106            0.843882            0.842105   \n21                42            0.848101            0.842105   \n22                15            0.852321            0.844211   \n23                50            0.852321            0.846316   \n24               106            0.862869            0.858947   \n25                15            0.862869            0.871579   \n26                50            0.862869            0.871579   \n27                 9            0.862869            0.867368   \n28               115            0.852321            0.865263   \n29                15            0.858650            0.856842   \n..               ...                 ...                 ...   \n114               87            0.898734            0.907368   \n115               77            0.902954            0.905263   \n116              115            0.871308            0.882105   \n117               60            0.879747            0.886316   \n118               65            0.879747            0.882105   \n119               77            0.879747            0.880000   \n120              133            0.964135            0.964211   \n121              113            0.985232            0.983158   \n122              120            0.985232            0.983158   \n123              124            0.985232            0.983158   \n124              115            0.905063            0.901053   \n125               60            0.902954            0.909474   \n126               29            0.905063            0.913684   \n127               65            0.911392            0.913684   \n128                9            0.879747            0.873684   \n129               29            0.888186            0.890526   \n130                6            0.881857            0.886316   \n131               15            0.886076            0.892632   \n132              144            0.972574            0.962105   \n133              133            0.985232            0.983158   \n134              115            0.985232            0.983158   \n135              132            0.985232            0.983158   \n136              138            0.919831            0.920000   \n137               95            0.934599            0.934737   \n138              113            0.943038            0.941053   \n139               77            0.945148            0.938947   \n140               65            0.898734            0.903158   \n141               77            0.902954            0.903158   \n142               87            0.900844            0.905263   \n143               65            0.900844            0.905263   \n\n     split2_train_score  mean_train_score  std_train_score  \n0              0.863158          0.855339         0.008082  \n1              0.865263          0.856041         0.008790  \n2              0.861053          0.859551         0.001920  \n3              0.863158          0.858848         0.003441  \n4              0.856842          0.854641         0.007775  \n5              0.856842          0.850424         0.007436  \n6              0.856842          0.855338         0.001918  \n7              0.858947          0.854636         0.004503  \n8              0.852632          0.846206         0.004601  \n9              0.858947          0.849718         0.006970  \n10             0.856842          0.851124         0.005226  \n11             0.858947          0.852528         0.005159  \n12             0.863158          0.855339         0.008082  \n13             0.865263          0.856041         0.008790  \n14             0.861053          0.859551         0.001920  \n15             0.863158          0.858848         0.003441  \n16             0.856842          0.854641         0.007775  \n17             0.856842          0.850424         0.007436  \n18             0.856842          0.855338         0.001918  \n19             0.858947          0.854636         0.004503  \n20             0.852632          0.846206         0.004601  \n21             0.858947          0.849718         0.006970  \n22             0.856842          0.851124         0.005226  \n23             0.858947          0.852528         0.005159  \n24             0.861053          0.860956         0.001603  \n25             0.875789          0.870079         0.005380  \n26             0.873684          0.869377         0.004682  \n27             0.867368          0.865869         0.002121  \n28             0.867368          0.861651         0.006653  \n29             0.869474          0.861655         0.005578  \n..                  ...               ...              ...  \n114            0.909474          0.905192         0.004647  \n115            0.907368          0.905195         0.001803  \n116            0.888421          0.880611         0.007066  \n117            0.884211          0.883424         0.002739  \n118            0.884211          0.882021         0.001823  \n119            0.892632          0.884126         0.006015  \n120            0.974737          0.967694         0.004980  \n121            0.989474          0.985955         0.002629  \n122            0.993684          0.987358         0.004553  \n123            0.993684          0.987358         0.004553  \n124            0.907368          0.904495         0.002610  \n125            0.920000          0.910809         0.007023  \n126            0.920000          0.912916         0.006122  \n127            0.920000          0.915026         0.003640  \n128            0.877895          0.877109         0.002537  \n129            0.894737          0.891150         0.002711  \n130            0.903158          0.890443         0.009173  \n131            0.903158          0.893955         0.007036  \n132            0.976842          0.970507         0.006191  \n133            0.991579          0.986656         0.003582  \n134            0.993684          0.987358         0.004553  \n135            0.993684          0.987358         0.004553  \n136            0.928421          0.922751         0.004010  \n137            0.932632          0.933989         0.000962  \n138            0.936842          0.940311         0.002583  \n139            0.938947          0.941014         0.002923  \n140            0.911579          0.904490         0.005328  \n141            0.911579          0.905897         0.004019  \n142            0.911579          0.905895         0.004405  \n143            0.907368          0.904492         0.002719  \n\n[144 rows x 22 columns]\nbest score: 0.8356741573033708\nbest parameters: {'max_depth': 5, 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 150, 'n_jobs': 8, 'random_state': 0}\nbest estimator test score: 0.8100558659217877\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def slected_model_prediction(model):\n    y_pre = model.predict(X_test)\n    train_score = model.score(X_train, y_train)\n\n    test = pd.read_csv('../input/test.csv')\n    # select one algorithm according to the performance on trainning set\n    output = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_pre})\n    output.to_csv('prediction.csv', index=False)\n    ","execution_count":81,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(max_depth=5, max_features=None, min_samples_leaf=2, n_estimators=150, \n                               n_jobs=8, random_state=0).fit(X_train, y_train)\n\nslected_model_prediction(model)","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"version":"3.6.4","name":"python","nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}